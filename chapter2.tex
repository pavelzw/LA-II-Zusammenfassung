\documentclass[main.tex]{subfiles}

\begin{document}

\section*{Geometrie von \(\R, \C\)-Vektorräumen}
\subsection*{Euklidische, unitäre VR}

\begin{karte}{Definition Bilinearform}
    Sei \(K\) ein Körper und \(V\) ein \(K\)-Vektorraum. 
    Eine Bilinearform auf \(V\) ist eine bilineare Abbildung 
    \(V \times V \rightarrow K\).\\
\end{karte}

\begin{karte}{Symmetrische Bilinearform}
    Eine Bilinearform \(\abb{b}{V\times V}{K}\) heißt symmetrisch,
    wenn
    \[ b(x,y) = b(y,x) \]
    für alle \(x, y \in V \) gilt. Eine Matrix heißt symmetrisch, 
    falls \(A^T = A\).\\
    \( b \) ist genau dann symmetrisch, wenn \( M_C(b) \) 
    symmetrisch ist.
\end{karte}

\begin{karte}{Definitheit von Bilinearformen}
    Eine Bilinearform \(b\) auf einem reellen Vektorraum \(V\) heißt
    \begin{description}
        \item[positiv definit,] falls \(b(x,x) > 0 \; \forall x \in V \setminus \set{0}\)
        \item[positiv semidefinit,] falls \(b(x,x) \geq 0 \; \forall x \in V\)
        \item[negativ definit,] falls \(b(x,x) < 0 \; \forall x \in V \setminus \set{0}\)
        \item[negativ semidefinit,] falls \(b(x,x) \leq 0 \; \forall x \in V\)
        \item[indefinit,] falls es \(x, y \in V \setminus \set{0}\) mit
        \(b(x,x) > 0\) und \(b(y,y) < 0\) gibt.  
    \end{description}
    Eine Matrix \(A\) heißt positiv definit, wenn
    die Bilinearform \( b(A) \) auf \(\R^n\) 
    positiv definit ist.
\end{karte}

\begin{karte}{Definition Skalarprodukt}
    Sei \(V\) ein \(\R\)-Vektorraum. Ein Skalarprodukt auf \(V\) ist eine
    symmetrische, positiv definite Bilinearform.\\
    Eine positive definite hermitesche Sesquilinearform heißt hermitesches Skalarprodukt.
\end{karte}

\begin{karte}{Definition Sesquilinearform}
    Sei \(V\) ein \(\C\)-Vektorraum. Eine Abbildung \(\abb{b}{V\times V}{\C}\)
    heißt \textit{Sesquilinearform}, wenn für jedes \(x\in V\) die Abbildung
    \[ \abb{b(x, \cdot)}{V}{\C} \]
    \(\C\)-linear ist und die Abbildung
    \[ \abb{b(\cdot, x)}{V}{\C} \]
    \(\R\)-linear ist und für jedes \(\lambda \in \C\) und \(y \in V\) gilt
    \[ b(\lambda y, x) = \overline{\lambda} b(y,x). \]
\end{karte}

\begin{karte}{Definition konjugiert linear}
    Eine reell lineare Abbildung \(\abb{f}{V}{W}\) zwischen komplexen Vektorräumen,
    die \(f(\lambda v) = \overline{\lambda}f(v)\) für jedes \(\lambda \in \C\)
    und \(v \in V\) erfüllt, heißt auch \textit{konjugiert linear}.
\end{karte}

\begin{karte}{Definition hermitesche Sesquilinearform}
    Sei \(\abb{b}{V\times V}{\C}\) eine Sesquilinearform. 
    Dann heißt \(b\) \textit{hermitesch},
    wenn für alle \(x,y \in V\)
    \[ b(x,y) = \overline{b(y,x)} \]
    gilt.\\
    Eine hermitesche Sesquilinearform \(b\) auf \(V\) heißt positiv definit,
    wenn \(b(x,x) > 0\) für alle \(x \in V \setminus \set{0}\)
\end{karte}

\begin{karte}{Definition adjungierte Matrix}
    Für eine Matrix \(A \in M_{m,n}(\C)\) ist ihre 
    adjungierte Matrix \(A^H \in M_{n,m}(\C)\)
    diejenige Matrix, die man erhält, wenn man 
    \(A\) transponiert und alle Matrixeinträge 
    komplex konjugiert. Man bezeichnet \(A^H\) 
    auch als das hermitesch Transponierte von \(A\).\\
    Es gelten die Rechenregeln:\\
    \[ \overline{A} + \overline{B} = \overline{A + B} \]
    \[ \overline{A} \cdot \overline{B} = \overline{AB} \]
    \[ A^H + B^H = (A + B)^H \]
    \[ B^H \cdot A^H = (A \cdot B)^H \]
\end{karte}

\begin{karte}{Definition euklidischer und unitärer Vektorraum}
    Ein euklidischer Vektorraum ist ein Paar bestehend aus einem reellen Vektorraum \(V\)
    und einem Skalarprodukt auf \(V\).\\
    Ein unitärer Vektorraum ist ein Paar bestehend aus einem komplexen Vektorraum \(V\) und
    einem hermiteschen Skalarprodukt auf \(V\).
\end{karte}

\begin{karte}{Definition Norm}
    Sei \(K\) der Körper der reellen oder komplexen Zahlen. Sei \(V\) ein \(K\)-Vektorraum.
    Eine Norm auf \(V\) ist eine Abbildung
    \[ \abb{\norm{\cdot}}{V}{[0, \infty)} \]
    mit folgenden Eigenschaften:
    \begin{description}
        \item[Homogenität] Für alle \(\lambda \in K\) und \(v \in V\) ist 
        \[ \norm{\lambda v} = \abs{\lambda} \norm{v}. \]
        \item[Definitheit] Es ist \(\norm{v} = 0\) genau dann, wenn \(v = 0\).
        \item[Dreiecksungleichung] Für alle \(v, w \in V\) ist
        \[ \norm{v+w} \leq \norm{v} + \norm{w}. \]   
    \end{description}
\end{karte}

\begin{karte}{Normierter Vektorraum}
    Sei \(K \in \set{\R, \C}\). Ein normierter \(K\)-Vektorraum ist ein Paar bestehend
    aus einem \(K\)-Vektorraum \(V\) und einer Norm auf \(V\).\\
    Normierte Vektorräume sind gleichzeitig metrische Räume mit
    \[ \abb{d}{V\times V}{[0, \infty)}, (x, y) \mapsto \norm{x-y}. \]
\end{karte}

\begin{karte}{Definition induzierte Norm}
    Sei \((V, \scalarprod{\cdot}{\cdot})\) ein euklidischer oder unitärer Vektorraum.
    Dann definieren wir durch
    \[ \abb{\norm{\cdot}}{V}{\R}, x \mapsto \sqrt{\scalarprod{x}{x}} \]
    die von \(\scalarprod{\cdot}{\cdot}\) induzierte Norm auf \(V\).\\
    \(\norm{\cdot}_2\) ist die von \(\scalarprod{\cdot}{\cdot}_2\) induzierte Norm und
    wird als euklidische Norm bezeichnet.\\
    Die Supremumsnorm ist definiert durch 
    \[ \abb{\norm{\cdot}_\infty}{\R^n}{[0,\infty)}, 
    x \mapsto \max\set{\abs{x_1}, \ldots, \abs{x_n}}. \]
\end{karte}

\begin{karte}{Ungleichung von Cauchy-Schwarz}
    Sei \((V, \scalarprod{\cdot}{\cdot})\) ein euklidischer oder unitärer Vektorraum
    und \(\norm{\cdot}\) eine Norm. Dann gilt
    \[ \abs{\scalarprod{x}{y}} \leq \norm{x} \cdot \norm{y}. \]
    Gleichheit tritt genau dann ein, wenn \(x\) und \(y\) linear abhängig sind.
\end{karte}

\begin{karte}{Polarisierung}
    Sei \((V, \scalarprod{\cdot}{\cdot})\) ein euklidischer oder unitärer Vektorraum mit induzierter
    Norm \(\norm{\cdot}\).
    \begin{enumerate}
        \item Im euklidischen Fall gilt für alle \(x, y \in V\)
        \[ \scalarprod{x}{y} = \frac{1}{2}(\norm{x+y}^2-\norm{x}^2-\norm{y}^2). \]
        \item Im unitären Fall gilt für alle \(x, y \in V\)
        \[ \scalarprod{x}{y} = \frac{1}{4}(\norm{x+y}^2-\norm{x-y}^2) 
        - \frac{i}{4}(\norm{x+iy}^2-\norm{x-iy}^2). \]
    \end{enumerate}
\end{karte}

\begin{karte}{Definition Winkel}
    Sei \((V, \scalarprod{\cdot}{\cdot})\) ein euklidischer Vektorraum mit induzierter Norm \(\norm{\cdot}\).
    Seien \(x, y \in V \setminus \set{0}\). Dann ist der Winkel zwischen \(x\) und \(y\) definiert als
    \[ \angle (x,y) := \arccos \frac{\scalarprod{x}{y}}{\norm{x} \norm{y}} \in [0, \pi]. \]
\end{karte}

\begin{karte}{Definition lineare isometrische Einbettung und lineare Isometrie}
    Seien \((V, \norm{\cdot})\) und \((V', \norm{\cdot}')\) normierte Vektorräume über 
    \(K \in \set{\R, \C}\).\\
    Eine lineare isometrische Einbettung \((V, \norm{\cdot}) \rightarrow (V', \norm{\cdot}')\)
    ist eine \(K\)-lineare Abbildung \(\abb{f}{V}{V'}\) mit
    \[ \norm{f(x)}' = \norm{x} \; \forall x \in V. \]
    Eine lineare Isometrie \((V, \norm{\cdot}) \rightarrow (V', \norm{\cdot}')\) ist eine
    bijektive lineare isometrische Einbettung \((V, \norm{\cdot}) \rightarrow (V', \norm{\cdot}')\).\\
    Lineare Isometrien sind winkeltreu, d. h. für alle \(x, y \in V \setminus \set{0}\) gilt
    \[ \angle (f(x), f(y)) = \angle (x,y) \]
\end{karte}

\begin{karte}{Definition orthogonale Matrix}
    Eine Matrix \(A \in \GL_n(\R)\) heißt orthogonal, falls
    \[ A^{-1} = A^T. \]
    Eine Matrix \(A \in \GL_n(\C)\) heißt unitär, alls
    \[A^{-1} = A^H.\]
\end{karte}

\begin{karte}{Wichtige Untergruppen von \(\GL_n\)}
    Die folgenden Teilmengen von \(\GL_n(\R)\) bzw. \(\GL_n(\C)\) sind Untergruppen:
    \begin{align*}
        \mathrm{O}(n) &:= \set{A \in \GL_n(\R) \vert A \text{ orthogonal}} &\text{orthogonale Gruppe}\\
        \mathrm{U}(n) &:= \set{A \in \GL_n(\R) \vert A \text{ unitär}} &\text{unitärer Gruppe}\\
        \mathrm{SO}(n) &:= \set{A \in \mathrm{O}(n) \vert \det A = 1} &\text{spezielle orthogonale Gruppe}\\
        \mathrm{SU}(n) &:= \set{A \in \mathrm{U}(n) \vert \det A = 1} &\text{spezielle unitäre Gruppe}
    \end{align*}
\end{karte}

\begin{karte}{Eigenschaften lineare Isometrie}
    Sei \(B = (v_1, \ldots, v_n)\) eine Orthonormalbasis des euklidischen oder unitären 
    Vektorraums \(V\). Sei \(\abb{f}{V}{V}\) ein Endomorphismus.
    \begin{enumerate}
        \item Es ist \(f\) eine lineare Isometrie genau dann, wenn \((f(v_1), \ldots, f(v_n))\)
        eine Orthonormalbasis ist.
        \item Es ist \(f\) eine lineare Isometrie genau dann, wenn \(M_{B,B}(f)\) orthogonal 
        bzw. unitär ist.
    \end{enumerate}
\end{karte}

\subsection*{Matrizenkalkül von Bilinearformen}

\begin{karte}{Bilinearformen Vektorraum}
    \( \Bil_K(V) \) ist die Menge der 
    Bilinearformen auf \( V \). \\
    Sie bildet einen \( K \)-Vektorraum.\\
    Sei \( V \) ein \(n\)-dimensionaler \(K\)-Vektorraum 
    und \( C=(c_1, \ldots, c_n) \) eine Basis von \(V\).
    Dann sind  
    \[ \abb{\phi}{\Bil_K(V)}{M_n(K)}, b\mapsto M_C(b) := (b(c_j, c_k))_{j,k\in\set{1,\ldots,n}} \]
    \[ \abb{\psi}{M_n(K)}{\Bil_K(V)}, A \mapsto b_C(A) \]
    zueinander inverse Isomorphismen.
\end{karte}

\begin{karte}{Basiswechsel Bilinearformen}
    Sei \(V\) ein \(n\)-dimensionaler \(K\)-Vektorraum. 
    Sei \( b\in \Bil_k(V) \). Sei \(C\) eine Basis 
    von \(V\) und \(A\in M_n(K)\). Dann sind 
    äquivalent:
    \begin{enumerate}
        \item Es gibt eine Matrix \(S\in \GL_n(K)\) mit 
        \[ A=S^T \cdot M_C(b) \cdot S. \]
        \item Es gibt eine Basis \( D \) von \(V\) mit
        \(A=M_D(b)\).
    \end{enumerate}
\end{karte}

\begin{karte}{Sesquilinearformen Vektorraum}
    \( \Sil_\C(V) \) ist die Menge der 
    Sesquilinearformen auf \( V \). \\
    Sie bildet einen \( \C \)-Vektorraum.\\
    Sei \( V \) ein \(n\)-dimensionaler \(\C\)-Vektorraum 
    und \( C=(c_1, \ldots, c_n) \) eine Basis von \(V\).
    Dann sind  
    \[ \abb{\phi}{\Sil_\C(V)}{M_n(\C)}, 
    b\mapsto M_C(b) := (b(c_j, c_k))_{j,k\in\set{1,\ldots,n}} \]
    \[ \abb{\psi}{M_n(\C)}{\Sil_\C(V)}, A \mapsto b^\C_C(A) \]
    zueinander inverse Isomorphismen.
\end{karte}

\begin{karte}{Basiswechsel Sesquilinearform}
    Sei \(V\) ein \(n\)-dimensionaler \(\C\)-Vektorraum. 
    Sei \(b \in \Sil_\C(V)\). Sei \(C\) eine Basis von 
    \(V\) und \(A\in M_n(\C)\). Dann sind äquivalent:
    \begin{enumerate}
        \item Es gibt eine Matrix \( S \in \GL_n(\C) \) mit 
        \[ A=S^H \cdot M_C(b) \cdot S. \]
        \item Es gibt eine Basis \(D\) von \( V \) 
        mit \( A=M_D(b) \).
    \end{enumerate}
\end{karte}

\begin{karte}{Hermitesch}
    Eine Matrix \(A\in M_n(\C)\) ist \textit{hermitesch} 
    oder \textit{selbstadjungiert}, wenn \(A^H=A\).\\
    Eine Sesquilinearform \( b \) ist genau dann 
    hermitesch, wenn \(M_C(b)\) hermitesch ist.
\end{karte}

\subsection*{Orthogonalität}

\begin{karte}{Orthogonal}
    Sei \( (V, \scalarprod{\cdot}{\cdot}) \) ein 
    euklidischer oder unitärer Vektorraum. 
    \begin{itemize}
        \item Zwei Vektoren \(v,w\in V\) heißen 
        \textit{orthogonal}, falls 
        \( \scalarprod{v}{w} = 0 \). In diesem Fall 
        schreiben wir auch \(v\bot w\).
        \item \( A, B \subset V \) heißen \textit{orthogonal}, 
        wenn für \( v\in A, w\in B \) stets \(v\bot w\) gilt.
        Schreiben \(A\bot B\).
        \item Ist \( A\subset V \), so nennen wir 
        \[ A^\bot := \set{ v\in V \;\vert\; v\bot w \text{ für alle } w\in A } \]
        das \textit{orthogonale Komplement} von \(A\). Das orthonale 
        Komplement ist ein Untervektorraum. \( U^\bot \) ist 
        komplementär zu \(U\).
    \end{itemize}
\end{karte}

\begin{karte}{Orthonormalsystem, Orthonormalbasis}
    Sei \( (V, \scalarprod{\cdot}{\cdot}) \) ein 
    euklidischer oder unitärer Vektorraum. 
    \begin{enumerate}
        \item Eine Familie \( (v_i)_{i\in I} \) 
        von Vektoren in \(V\) ist ein 
        \textit{Orthonormalsystem}, wenn für alle 
        \( i,j \in I \) gilt.
        \[ \scalarprod{v_i}{v_j} = \delta_{i,j}. \]
        \item Eine Orthonormalbasis von 
        \( (V, \scalarprod{\cdot}{\cdot}) \) ist 
        eine Basis von \(V\), die ein Orthonormalsystem ist.
    \end{enumerate}
    Jedes Orthonormalsystem ist linear unabhängig.\\
    Jeder endlich-dimensionale euklidische oder 
    unitäre Vektorraum besitzt eine Orthonormalbasis.
\end{karte}

\begin{karte}{Orthonormalisierungsverfahren von Gram-Schmidt}
   Sei \( (V, \scalarprod{\cdot}{\cdot}) \) ein 
   euklidischer oder unitärer Vektorraum. Es sei 
   \( (v_1,\ldots, v_n) \) eine linear unabhängiges 
   \(n\)-Tupel in \(V\). Dann gibt es ein 
   Orthonormalsystem \( (w_1, \ldots, w_n) \) in \(V\) 
   mit 
   \[ \langle \set{w_1, \ldots, w_k} \rangle 
   = \langle \set{ v_1, \ldots, v_k } \rangle \quad 
   \forall k \in \set{1,\ldots, n}. \]
   Weiter gilt: Das \(n\)-Tupel 
   \( (w_1, \ldots, w_n) \), das rekursiv durch 
   \[ w_1 := \frac{1}{\norm{\tilde{w}_1}} \cdot \tilde{w}_1 
   \text{ und } \tilde{w}_1 := v_1 \]
   und 
   \[ w_{k+1} := \frac{1}{\norm{ \tilde{w}_{k+1} }} 
   \cdot \tilde{w}_{k+1} \text{ und } 
   \tilde{w}_{k+1} := 
   v_{k+1} - \sum_{j=1}^k \scalarprod{w_j}{v_{k+1}} \cdot w_j \]
   für \( k\in \set{1, \ldots, n-1} \) definiert ist, hat 
   diese Eigenschaft.
\end{karte}

\begin{karte}{Isometrie zwischen Vektorräumen}
    Sei \( (V, \scalarprod{\cdot}{\cdot}) \) ein 
    endlich-dimensionaler euklidischer oder 
    unitärer Vektorraum mit Grundkörper 
    \( K\in \set{\R, \C} \). Dann gibt es eine lineare 
    Isometrie zwischen \( (K^n, \scalarprod{\cdot}{\cdot}_2) \)
    und \( (V, \scalarprod{\cdot}{\cdot}) \).
\end{karte}

\begin{karte}{Orthogonale Projektion}
    Sei \( (V,\scalarprod{\cdot}{\cdot}) \) ein 
    euklidischer oder unitärer Vektorraum und 
    sei \( U \subset V \) ein endlich-dimensionaler 
    Untervektorraum. Dann gibt es genau eine lineare 
    Abbildung \( \abb{p_U}{V}{V} \) mit folgenden 
    Eigenschaften:
    \begin{enumerate}
        \item Es gilt \(\Bild(p_U) \subset U\).
        \item Es gilt \( \Bild(p_U - \id_V)\subset U^\bot \).
    \end{enumerate}
    Weiter ist \( p_U(x) = x \) für \( x\in U \). Man 
    bezeichnet \( p_U \) als \textit{orthogonale Projektion} 
    von \(V\) auf \(U\).
\end{karte}

\subsection*{Selbstadjungierte Endomorphismen}

\begin{karte}{Selbstadjungiert}
    Ein Endomorphismus \( \abb{f}{V}{V} \) heißt 
    \textit{selbstadjungiert}, wenn für alle 
    \( x,y\in V \) gilt:
    \[ \scalarprod{x}{f(y)} = \scalarprod{f(x)}{y}. \]
    Eine komplexe Matrix ist selbstadjungiert, wenn 
    \( A^H = A \) und wenn alle Matrixeinträge reell 
    sind, ist sie selbstadjungiert, wenn \(A^T = A\).
    \( M_{B,B}(f) \) ist genau dann selbstadjungiert, 
    wenn \(f\) selbstadjungiert ist.
\end{karte}

\begin{karte}{Adjungierte Abbildung}
    Sei \( \abb{f}{V}{V} \) ein Endomorphismus 
    eines endlich-dimensionalen euklidischen oder unitären 
    Vektorraums. Dann gibt es genau einen Endomorphismus 
    \( \abb{f^H}{V}{V} \) so, dass 
    \[ \scalarprod{x}{f(y)} = \scalarprod{f^H(x)}{y} \] 
    für alle \( x,y\in V \) gilt. \\
    Man bezeichnet \(f^H\) als adjungierte Abbildung 
    von \(f\).\\
    Ein Endomorphismus \(f\) ist genau dann selbstadjungiert, 
    wenn \(f^H = f\).
    Es gilt außerdem 
    \[ M_{B,B}(f^H) = M_{B, B}(f)^H. \]
\end{karte}

\begin{karte}{Rechenregeln adjungierte Abbildung}
    Seien \(\abb{f,g}{V}{V}\) Endomorphismen eines 
    endlich-dimensionalen euklidischen oder unitären 
    Vektorraums. Seien \( \lambda, \mu\in \C \). Dann 
    gilt 
    \begin{enumerate}
        \item \( (\lambda \cdot f + \mu \cdot g)^H 
        = \overline{\lambda} \cdot f^H + \overline{\mu} \cdot g^H \).
        \item \( (f^H)^H =f \).
    \end{enumerate}
\end{karte}

\begin{karte}{Spektralsatz für selbstadjungierte Endomorphismen}
    Sei \( \abb{f}{V}{V} \) ein selbstadjungierte Endomorphismus 
    eines \\
    endlich-dimensionalen euklidischen oder unitären 
    Vektorraums. Es bezeichne \( K\in \set{\R, \C} \) 
    den Grundkörper von \(V\). Dann gilt 
    \begin{enumerate}
        \item \( \spec_K(f) \subset \R \).
        \item Es gibt eine Orthonormalbasis von \(V\) 
        aus Eigenvektoren von \(f\). Insbesondere ist 
        \(f\) diagonalisierbar.
    \end{enumerate}
\end{karte}

\begin{karte}{Diagonalisierung symmetrischer Matrizen}
    Ist die Matrix \( A\in M_n(\R) \) symmetrisch, 
    so gibt es ein \( S\in \mathrm{O}(n) \) so, dass 
    \[ S^T \cdot A \cdot S = S^{-1} \cdot A\cdot S 
    = \begin{pmatrix}
        \lambda_1 && 0 \\
        & \ddots & \\
        0 && \lambda_n
    \end{pmatrix} \]
    eine Diagonalmatrix mit reellen Einträgen ist.
\end{karte}

\begin{karte}{Diagonalisierung hermitescher Matrizen}
    Ist die Matrix \( A\in M_n(\C) \) hermitesch, so gibt es 
    ein \( S\in \mathrm{U}(n) \) hermitesch so, dass 
    \[ S^H \cdot A \cdot S = S^{-1} \cdot A \cdot S 
    = \begin{pmatrix}
        \lambda_1 && 0 \\
        & \ddots & \\
        0 && \lambda_n
    \end{pmatrix} \]
    eine Diagonalmatrix mit reellen Einträgen ist.
\end{karte}

\begin{karte}{Normale Endomorphismen}
    Wir nennen einen Endomorphismus 
    \( f \) eines euklidischen oder unitären 
    Vektorraums endlicher Dimension \textit{normal}, 
    wenn 
    \[ f^H \circ f = f \circ f^H. \]
    Ist \( f \) normal, dann auch \( \mu \cdot f \) 
    und \( f + \mu \cdot \id_V \). 
\end{karte}

\begin{karte}{Spektralsatz für normale Endomorphismen}
    Sei \( f \) ein Endomorphismus eines endlich-dimensionalen 
    euklidischen oder \\
    unitären Vektorraums, dessen 
    charakterisches Polynom in Linearfaktoren \\
    zerfällt. 
    Dann gibt es genau dann eine Orthonormalbasis aus 
    Eigenvektoren von \(f\), wenn \(f\) normal ist.
\end{karte}

\begin{karte}{Eigenschaften normale Endomorphismen}
    Sei \(\abb{f}{V}{V}\) normal. Dann gilt: 
    \begin{enumerate}
        \item \( \ker f = \ker f^H \).
        \item Ein Vektor \(v\in V\) ist genau dann ein 
        Eigenvektor von \(f\) zum Eigenwert \(\lambda\), 
        wenn \(v\) ein Eigenvektor von \( f^H \) zum 
        Eigenwert \( \overline{\lambda} \) ist.
    \end{enumerate}
\end{karte}

\begin{karte}{Definitheit symmetrischer Matrizen}
    Sei \( A\in M_n(\R) \) symmetrisch. Dann ist \(A\)
    \begin{itemize}
        \item genau dann positiv definit, 
        wenn \( \spec_\R(A) \subset (0,\infty) \).
        \item genau dann positiv semidefinit, 
        wenn \( \spec_\R(A) \subset [0,\infty) \).
        \item genau dann negativ definit, 
        wenn \( \spec_\R(A) \subset (-\infty, 0) \).
        \item genau dann negativ semidefinit, 
        wenn \( \spec_\R(A) \subset (-\infty, 0] \).
        \item genau dann indefinit, wenn 
        \( \spec_\R(A) \) negative und positive Zahlen 
        enthält.
    \end{itemize}
\end{karte}

\begin{karte}{\(k\)-ter Hauptminor}
    Sei \(A = (a_{i,j}) \in M_n(K)\) eine 
    quadratische Matrix über einem beliebigen Körper. 
    Sei \( 1 \leq k\leq n \). Die Determinante der 
    linken oberen \( k\times k \)-Teilmatrix 
    \( (a_{i,j})_{1\leq i,j \leq k} \) heißt 
    \textit{\(k\)-ter Hauptminor} von \(A\).
\end{karte}

\begin{karte}{Hurwitz-Kriterium}
    Eine reelle symmetrische Matrix \(A\) ist genau dann 
    positiv definit, wenn alle ihre Hauptminoren 
    positiv sind.\\
    \(A\) ist genau dann negativ definit, wenn 
    \(-A\) positiv definit ist oder 
    wenn die Hauptminoren alternierend positiv und 
    negativ sind (startend mit negativ).
\end{karte}

\end{document}